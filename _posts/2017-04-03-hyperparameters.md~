---
layout: post
title: Mining weather conditions
date: "04/03/2017"
---


number of input features
gpu/cpu configuration
training data

impossible to correctly guess the correct hyperparameters-iterative process of finding a good choice of network.

How efficient you can cycle:

Train/validation set/Test sets
dev test just big enough-not whole 20% of data
same is the case with test case (10k might be enough with 1mil examples)
Traditional ratios with small data sets
Distribution should be the same (getting data from different sources)

bias/variance tradeoff 

if train error << dev error (over-fitting) (high variance)
Bayes set- look at train/dev set to see if high variance or high bias
 


* 
