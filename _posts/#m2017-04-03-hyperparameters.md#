---
layout: post
title: Mining weather conditions
date: "04/03/2017"
---


number of input features
gpu/cpu configuration
training data

impossible to correctly guess the correct hyperparameters-iterative process of finding a good choice of network.

How efficient you can cycle:

Train/validation set/Test sets
dev test just big enough-not whole 20% of data
same is the case with test case (10k might be enough with 1mil examples)
Traditional ratios with small data sets
Distribution should be the same (getting data from different sources)

bias/variance tradeoff 

if train error << dev error (over-fitting) (high variance)
Bayes set- look at train/dev set to see if high variance or high bias
 
L1 and L2 regularization

regularization parameter - using cross validation/validation set

Frobenius norm of a matrix

Drop out regularization:

Separate optimization and over-fitting-decouple these

l2 over early stopping to decouple-but need to set hyperparameter


NORMALIZE THE INPUTS:

use same mean and sd


Initialization: speed up convergence
Increase the odds of gd converging to lower training error
Vanishing/exploding gradients

Deep learning flexible enough to cause over-fitting

really iterative process

works on big data-slow 

stochastic-loose speed up by vectorization
batch descent- too big
so something in between for value of batch size (64,128,256,512,1024)

minibatch in CPU/GPU memory - hyperparameter

